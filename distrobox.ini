[sar-lab]
image=ubuntu:24.04
pull=true
nvidia=true
start_now=true

# --- THE VAULT MOUNT ---
# Maps the ZFS HDD into the container at the exact same path
volume="/mnt/vault/sar_data:/mnt/vault/sar_data"

# --- SYSTEM DEPENDENCIES (Stable APT) ---
additional_packages="git curl wget build-essential clang cmake"
additional_packages="gdal-bin libgdal-dev libnetcdf-dev libhdf5-dev"
additional_packages="htop nvtop tmux ripgrep fd-find"
additional_packages="zoxide fzf nodejs"

# --- DRL & RENDERING DEPENDENCIES ---
# Required for OpenCV, Gymnasium, and MuJoCo rendering
additional_packages="libgl1 libglx-mesa0 libosmesa6 libglu1-mesa libegl1 libgles2 xvfb"

# --- ENTRY HOOKS (Runtime Config) ---
# 1. Add User-NPM and Local Binaries to PATH (Sharing host tools)
entry_hooks="export PATH=$HOME/.npm-global/bin:$HOME/.local/bin:$PATH"

# 2. Force uv behavior
entry_hooks="export UV_VENV_IN_PROJECT=1"

# ==========================================
# PHASE 2: THE BRAIN (Local LLMs)
# ==========================================
[ai-lab]
image=ubuntu:24.04
pull=true
nvidia=true
start_now=true

# Minimal packages needed to install and run Ollama
additional_packages="curl git systemd"

# Note: No custom volumes here. Models download to ~/.ollama 
# on your NVMe for maximum speed during this testing phase.
